{
  "best_global_step": 3639,
  "best_metric": 0.909253999103005,
  "best_model_checkpoint": "./bert_model/checkpoint-3639",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3639,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013740038472107722,
      "grad_norm": 3.639718532562256,
      "learning_rate": 1.6333333333333335e-06,
      "loss": 0.6998,
      "step": 50
    },
    {
      "epoch": 0.027480076944215445,
      "grad_norm": 3.9702308177948,
      "learning_rate": 3.3000000000000006e-06,
      "loss": 0.6926,
      "step": 100
    },
    {
      "epoch": 0.041220115416323165,
      "grad_norm": 6.014570713043213,
      "learning_rate": 4.966666666666667e-06,
      "loss": 0.6536,
      "step": 150
    },
    {
      "epoch": 0.05496015388843089,
      "grad_norm": 9.140778541564941,
      "learning_rate": 6.633333333333334e-06,
      "loss": 0.5739,
      "step": 200
    },
    {
      "epoch": 0.0687001923605386,
      "grad_norm": 7.78902530670166,
      "learning_rate": 8.3e-06,
      "loss": 0.4539,
      "step": 250
    },
    {
      "epoch": 0.08244023083264633,
      "grad_norm": 18.361522674560547,
      "learning_rate": 9.966666666666667e-06,
      "loss": 0.3446,
      "step": 300
    },
    {
      "epoch": 0.09618026930475405,
      "grad_norm": 4.982260704040527,
      "learning_rate": 9.95384760290101e-06,
      "loss": 0.3008,
      "step": 350
    },
    {
      "epoch": 0.10992030777686178,
      "grad_norm": 24.626338958740234,
      "learning_rate": 9.906753320146934e-06,
      "loss": 0.2307,
      "step": 400
    },
    {
      "epoch": 0.1236603462489695,
      "grad_norm": 1.3246723413467407,
      "learning_rate": 9.859659037392862e-06,
      "loss": 0.1823,
      "step": 450
    },
    {
      "epoch": 0.1374003847210772,
      "grad_norm": 22.065547943115234,
      "learning_rate": 9.812564754638788e-06,
      "loss": 0.2501,
      "step": 500
    },
    {
      "epoch": 0.15114042319318494,
      "grad_norm": 0.22605758905410767,
      "learning_rate": 9.765470471884714e-06,
      "loss": 0.2646,
      "step": 550
    },
    {
      "epoch": 0.16488046166529266,
      "grad_norm": 2.8688533306121826,
      "learning_rate": 9.71837618913064e-06,
      "loss": 0.1744,
      "step": 600
    },
    {
      "epoch": 0.17862050013740038,
      "grad_norm": 24.542173385620117,
      "learning_rate": 9.671281906376567e-06,
      "loss": 0.3042,
      "step": 650
    },
    {
      "epoch": 0.1923605386095081,
      "grad_norm": 13.883462905883789,
      "learning_rate": 9.624187623622493e-06,
      "loss": 0.3029,
      "step": 700
    },
    {
      "epoch": 0.20610057708161583,
      "grad_norm": 0.5340740084648132,
      "learning_rate": 9.577093340868419e-06,
      "loss": 0.234,
      "step": 750
    },
    {
      "epoch": 0.21984061555372356,
      "grad_norm": 23.383056640625,
      "learning_rate": 9.529999058114345e-06,
      "loss": 0.2299,
      "step": 800
    },
    {
      "epoch": 0.23358065402583128,
      "grad_norm": 0.12226317077875137,
      "learning_rate": 9.482904775360271e-06,
      "loss": 0.2626,
      "step": 850
    },
    {
      "epoch": 0.247320692497939,
      "grad_norm": 0.31661996245384216,
      "learning_rate": 9.4358104926062e-06,
      "loss": 0.1679,
      "step": 900
    },
    {
      "epoch": 0.26106073097004673,
      "grad_norm": 25.28339385986328,
      "learning_rate": 9.388716209852124e-06,
      "loss": 0.2096,
      "step": 950
    },
    {
      "epoch": 0.2748007694421544,
      "grad_norm": 0.08333873003721237,
      "learning_rate": 9.341621927098052e-06,
      "loss": 0.1883,
      "step": 1000
    },
    {
      "epoch": 0.2885408079142622,
      "grad_norm": 0.11520393937826157,
      "learning_rate": 9.294527644343976e-06,
      "loss": 0.1781,
      "step": 1050
    },
    {
      "epoch": 0.3022808463863699,
      "grad_norm": 20.897340774536133,
      "learning_rate": 9.247433361589904e-06,
      "loss": 0.2344,
      "step": 1100
    },
    {
      "epoch": 0.3160208848584776,
      "grad_norm": 0.22681301832199097,
      "learning_rate": 9.20033907883583e-06,
      "loss": 0.1886,
      "step": 1150
    },
    {
      "epoch": 0.3297609233305853,
      "grad_norm": 0.1864660531282425,
      "learning_rate": 9.153244796081757e-06,
      "loss": 0.2171,
      "step": 1200
    },
    {
      "epoch": 0.34350096180269307,
      "grad_norm": 31.49995994567871,
      "learning_rate": 9.106150513327683e-06,
      "loss": 0.1697,
      "step": 1250
    },
    {
      "epoch": 0.35724100027480077,
      "grad_norm": 0.07355180382728577,
      "learning_rate": 9.059056230573609e-06,
      "loss": 0.2239,
      "step": 1300
    },
    {
      "epoch": 0.37098103874690846,
      "grad_norm": 0.24620909988880157,
      "learning_rate": 9.011961947819535e-06,
      "loss": 0.2138,
      "step": 1350
    },
    {
      "epoch": 0.3847210772190162,
      "grad_norm": 15.003326416015625,
      "learning_rate": 8.964867665065462e-06,
      "loss": 0.3073,
      "step": 1400
    },
    {
      "epoch": 0.3984611156911239,
      "grad_norm": 0.08426138013601303,
      "learning_rate": 8.917773382311388e-06,
      "loss": 0.1531,
      "step": 1450
    },
    {
      "epoch": 0.41220115416323166,
      "grad_norm": 14.317792892456055,
      "learning_rate": 8.870679099557314e-06,
      "loss": 0.182,
      "step": 1500
    },
    {
      "epoch": 0.42594119263533936,
      "grad_norm": 0.8186487555503845,
      "learning_rate": 8.823584816803242e-06,
      "loss": 0.1466,
      "step": 1550
    },
    {
      "epoch": 0.4396812311074471,
      "grad_norm": 18.319841384887695,
      "learning_rate": 8.776490534049166e-06,
      "loss": 0.1921,
      "step": 1600
    },
    {
      "epoch": 0.4534212695795548,
      "grad_norm": 0.08368849754333496,
      "learning_rate": 8.729396251295094e-06,
      "loss": 0.1833,
      "step": 1650
    },
    {
      "epoch": 0.46716130805166256,
      "grad_norm": 1.79403817653656,
      "learning_rate": 8.68230196854102e-06,
      "loss": 0.2139,
      "step": 1700
    },
    {
      "epoch": 0.48090134652377026,
      "grad_norm": 13.724562644958496,
      "learning_rate": 8.635207685786947e-06,
      "loss": 0.1906,
      "step": 1750
    },
    {
      "epoch": 0.494641384995878,
      "grad_norm": 9.742436408996582,
      "learning_rate": 8.588113403032873e-06,
      "loss": 0.1533,
      "step": 1800
    },
    {
      "epoch": 0.5083814234679858,
      "grad_norm": 0.20854806900024414,
      "learning_rate": 8.541019120278799e-06,
      "loss": 0.1408,
      "step": 1850
    },
    {
      "epoch": 0.5221214619400935,
      "grad_norm": 0.11648739129304886,
      "learning_rate": 8.493924837524725e-06,
      "loss": 0.1799,
      "step": 1900
    },
    {
      "epoch": 0.5358615004122012,
      "grad_norm": 0.02938375435769558,
      "learning_rate": 8.446830554770652e-06,
      "loss": 0.1132,
      "step": 1950
    },
    {
      "epoch": 0.5496015388843088,
      "grad_norm": 0.03255586326122284,
      "learning_rate": 8.399736272016578e-06,
      "loss": 0.2667,
      "step": 2000
    },
    {
      "epoch": 0.5633415773564165,
      "grad_norm": 0.09896139055490494,
      "learning_rate": 8.352641989262504e-06,
      "loss": 0.1424,
      "step": 2050
    },
    {
      "epoch": 0.5770816158285244,
      "grad_norm": 0.09275360405445099,
      "learning_rate": 8.30554770650843e-06,
      "loss": 0.1446,
      "step": 2100
    },
    {
      "epoch": 0.590821654300632,
      "grad_norm": 39.59969711303711,
      "learning_rate": 8.258453423754356e-06,
      "loss": 0.1713,
      "step": 2150
    },
    {
      "epoch": 0.6045616927727397,
      "grad_norm": 0.7177359461784363,
      "learning_rate": 8.211359141000284e-06,
      "loss": 0.0984,
      "step": 2200
    },
    {
      "epoch": 0.6183017312448474,
      "grad_norm": 49.079681396484375,
      "learning_rate": 8.164264858246209e-06,
      "loss": 0.1811,
      "step": 2250
    },
    {
      "epoch": 0.6320417697169552,
      "grad_norm": 25.57713508605957,
      "learning_rate": 8.117170575492135e-06,
      "loss": 0.1492,
      "step": 2300
    },
    {
      "epoch": 0.645781808189063,
      "grad_norm": 29.069976806640625,
      "learning_rate": 8.070076292738063e-06,
      "loss": 0.2038,
      "step": 2350
    },
    {
      "epoch": 0.6595218466611706,
      "grad_norm": 4.703706741333008,
      "learning_rate": 8.022982009983988e-06,
      "loss": 0.1579,
      "step": 2400
    },
    {
      "epoch": 0.6732618851332783,
      "grad_norm": 53.392356872558594,
      "learning_rate": 7.975887727229915e-06,
      "loss": 0.1916,
      "step": 2450
    },
    {
      "epoch": 0.6870019236053861,
      "grad_norm": 0.09075982868671417,
      "learning_rate": 7.92879344447584e-06,
      "loss": 0.1582,
      "step": 2500
    },
    {
      "epoch": 0.7007419620774938,
      "grad_norm": 8.762046813964844,
      "learning_rate": 7.881699161721768e-06,
      "loss": 0.2129,
      "step": 2550
    },
    {
      "epoch": 0.7144820005496015,
      "grad_norm": 0.4255253076553345,
      "learning_rate": 7.834604878967694e-06,
      "loss": 0.1245,
      "step": 2600
    },
    {
      "epoch": 0.7282220390217092,
      "grad_norm": 0.029928814619779587,
      "learning_rate": 7.78751059621362e-06,
      "loss": 0.1374,
      "step": 2650
    },
    {
      "epoch": 0.7419620774938169,
      "grad_norm": 1.2551265954971313,
      "learning_rate": 7.740416313459547e-06,
      "loss": 0.1698,
      "step": 2700
    },
    {
      "epoch": 0.7557021159659247,
      "grad_norm": 38.74884033203125,
      "learning_rate": 7.693322030705473e-06,
      "loss": 0.1292,
      "step": 2750
    },
    {
      "epoch": 0.7694421544380324,
      "grad_norm": 0.018076233565807343,
      "learning_rate": 7.646227747951399e-06,
      "loss": 0.1265,
      "step": 2800
    },
    {
      "epoch": 0.7831821929101401,
      "grad_norm": 12.16530704498291,
      "learning_rate": 7.599133465197326e-06,
      "loss": 0.1918,
      "step": 2850
    },
    {
      "epoch": 0.7969222313822478,
      "grad_norm": 0.06284032016992569,
      "learning_rate": 7.552039182443251e-06,
      "loss": 0.1838,
      "step": 2900
    },
    {
      "epoch": 0.8106622698543556,
      "grad_norm": 4.303733825683594,
      "learning_rate": 7.5049448996891785e-06,
      "loss": 0.0993,
      "step": 2950
    },
    {
      "epoch": 0.8244023083264633,
      "grad_norm": 17.671188354492188,
      "learning_rate": 7.457850616935105e-06,
      "loss": 0.2026,
      "step": 3000
    },
    {
      "epoch": 0.838142346798571,
      "grad_norm": 45.796783447265625,
      "learning_rate": 7.410756334181031e-06,
      "loss": 0.2012,
      "step": 3050
    },
    {
      "epoch": 0.8518823852706787,
      "grad_norm": 4.688870429992676,
      "learning_rate": 7.363662051426957e-06,
      "loss": 0.161,
      "step": 3100
    },
    {
      "epoch": 0.8656224237427865,
      "grad_norm": 11.649136543273926,
      "learning_rate": 7.316567768672884e-06,
      "loss": 0.1502,
      "step": 3150
    },
    {
      "epoch": 0.8793624622148942,
      "grad_norm": 0.1611730456352234,
      "learning_rate": 7.2694734859188095e-06,
      "loss": 0.1474,
      "step": 3200
    },
    {
      "epoch": 0.8931025006870019,
      "grad_norm": 13.643877983093262,
      "learning_rate": 7.222379203164737e-06,
      "loss": 0.1721,
      "step": 3250
    },
    {
      "epoch": 0.9068425391591096,
      "grad_norm": 83.33094787597656,
      "learning_rate": 7.175284920410662e-06,
      "loss": 0.1574,
      "step": 3300
    },
    {
      "epoch": 0.9205825776312173,
      "grad_norm": 4.787201404571533,
      "learning_rate": 7.128190637656589e-06,
      "loss": 0.1862,
      "step": 3350
    },
    {
      "epoch": 0.9343226161033251,
      "grad_norm": 0.013330822810530663,
      "learning_rate": 7.081096354902516e-06,
      "loss": 0.0883,
      "step": 3400
    },
    {
      "epoch": 0.9480626545754328,
      "grad_norm": 0.10052993148565292,
      "learning_rate": 7.0340020721484415e-06,
      "loss": 0.1831,
      "step": 3450
    },
    {
      "epoch": 0.9618026930475405,
      "grad_norm": 76.99364471435547,
      "learning_rate": 6.9869077893943685e-06,
      "loss": 0.1629,
      "step": 3500
    },
    {
      "epoch": 0.9755427315196482,
      "grad_norm": 4.9555277824401855,
      "learning_rate": 6.939813506640295e-06,
      "loss": 0.1294,
      "step": 3550
    },
    {
      "epoch": 0.989282769991756,
      "grad_norm": 0.04486240819096565,
      "learning_rate": 6.892719223886221e-06,
      "loss": 0.1477,
      "step": 3600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9165979664743061,
      "eval_f1": 0.909253999103005,
      "eval_loss": 0.3291667401790619,
      "eval_precision": 0.9947661105659142,
      "eval_recall": 0.8372797356828194,
      "eval_runtime": 241.5354,
      "eval_samples_per_second": 30.132,
      "eval_steps_per_second": 3.768,
      "step": 3639
    }
  ],
  "logging_steps": 50,
  "max_steps": 10917,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7659425932584960.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
