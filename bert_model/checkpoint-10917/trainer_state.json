{
  "best_global_step": 3639,
  "best_metric": 0.909253999103005,
  "best_model_checkpoint": "./bert_model/checkpoint-3639",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 10917,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013740038472107722,
      "grad_norm": 3.639718532562256,
      "learning_rate": 1.6333333333333335e-06,
      "loss": 0.6998,
      "step": 50
    },
    {
      "epoch": 0.027480076944215445,
      "grad_norm": 3.9702308177948,
      "learning_rate": 3.3000000000000006e-06,
      "loss": 0.6926,
      "step": 100
    },
    {
      "epoch": 0.041220115416323165,
      "grad_norm": 6.014570713043213,
      "learning_rate": 4.966666666666667e-06,
      "loss": 0.6536,
      "step": 150
    },
    {
      "epoch": 0.05496015388843089,
      "grad_norm": 9.140778541564941,
      "learning_rate": 6.633333333333334e-06,
      "loss": 0.5739,
      "step": 200
    },
    {
      "epoch": 0.0687001923605386,
      "grad_norm": 7.78902530670166,
      "learning_rate": 8.3e-06,
      "loss": 0.4539,
      "step": 250
    },
    {
      "epoch": 0.08244023083264633,
      "grad_norm": 18.361522674560547,
      "learning_rate": 9.966666666666667e-06,
      "loss": 0.3446,
      "step": 300
    },
    {
      "epoch": 0.09618026930475405,
      "grad_norm": 4.982260704040527,
      "learning_rate": 9.95384760290101e-06,
      "loss": 0.3008,
      "step": 350
    },
    {
      "epoch": 0.10992030777686178,
      "grad_norm": 24.626338958740234,
      "learning_rate": 9.906753320146934e-06,
      "loss": 0.2307,
      "step": 400
    },
    {
      "epoch": 0.1236603462489695,
      "grad_norm": 1.3246723413467407,
      "learning_rate": 9.859659037392862e-06,
      "loss": 0.1823,
      "step": 450
    },
    {
      "epoch": 0.1374003847210772,
      "grad_norm": 22.065547943115234,
      "learning_rate": 9.812564754638788e-06,
      "loss": 0.2501,
      "step": 500
    },
    {
      "epoch": 0.15114042319318494,
      "grad_norm": 0.22605758905410767,
      "learning_rate": 9.765470471884714e-06,
      "loss": 0.2646,
      "step": 550
    },
    {
      "epoch": 0.16488046166529266,
      "grad_norm": 2.8688533306121826,
      "learning_rate": 9.71837618913064e-06,
      "loss": 0.1744,
      "step": 600
    },
    {
      "epoch": 0.17862050013740038,
      "grad_norm": 24.542173385620117,
      "learning_rate": 9.671281906376567e-06,
      "loss": 0.3042,
      "step": 650
    },
    {
      "epoch": 0.1923605386095081,
      "grad_norm": 13.883462905883789,
      "learning_rate": 9.624187623622493e-06,
      "loss": 0.3029,
      "step": 700
    },
    {
      "epoch": 0.20610057708161583,
      "grad_norm": 0.5340740084648132,
      "learning_rate": 9.577093340868419e-06,
      "loss": 0.234,
      "step": 750
    },
    {
      "epoch": 0.21984061555372356,
      "grad_norm": 23.383056640625,
      "learning_rate": 9.529999058114345e-06,
      "loss": 0.2299,
      "step": 800
    },
    {
      "epoch": 0.23358065402583128,
      "grad_norm": 0.12226317077875137,
      "learning_rate": 9.482904775360271e-06,
      "loss": 0.2626,
      "step": 850
    },
    {
      "epoch": 0.247320692497939,
      "grad_norm": 0.31661996245384216,
      "learning_rate": 9.4358104926062e-06,
      "loss": 0.1679,
      "step": 900
    },
    {
      "epoch": 0.26106073097004673,
      "grad_norm": 25.28339385986328,
      "learning_rate": 9.388716209852124e-06,
      "loss": 0.2096,
      "step": 950
    },
    {
      "epoch": 0.2748007694421544,
      "grad_norm": 0.08333873003721237,
      "learning_rate": 9.341621927098052e-06,
      "loss": 0.1883,
      "step": 1000
    },
    {
      "epoch": 0.2885408079142622,
      "grad_norm": 0.11520393937826157,
      "learning_rate": 9.294527644343976e-06,
      "loss": 0.1781,
      "step": 1050
    },
    {
      "epoch": 0.3022808463863699,
      "grad_norm": 20.897340774536133,
      "learning_rate": 9.247433361589904e-06,
      "loss": 0.2344,
      "step": 1100
    },
    {
      "epoch": 0.3160208848584776,
      "grad_norm": 0.22681301832199097,
      "learning_rate": 9.20033907883583e-06,
      "loss": 0.1886,
      "step": 1150
    },
    {
      "epoch": 0.3297609233305853,
      "grad_norm": 0.1864660531282425,
      "learning_rate": 9.153244796081757e-06,
      "loss": 0.2171,
      "step": 1200
    },
    {
      "epoch": 0.34350096180269307,
      "grad_norm": 31.49995994567871,
      "learning_rate": 9.106150513327683e-06,
      "loss": 0.1697,
      "step": 1250
    },
    {
      "epoch": 0.35724100027480077,
      "grad_norm": 0.07355180382728577,
      "learning_rate": 9.059056230573609e-06,
      "loss": 0.2239,
      "step": 1300
    },
    {
      "epoch": 0.37098103874690846,
      "grad_norm": 0.24620909988880157,
      "learning_rate": 9.011961947819535e-06,
      "loss": 0.2138,
      "step": 1350
    },
    {
      "epoch": 0.3847210772190162,
      "grad_norm": 15.003326416015625,
      "learning_rate": 8.964867665065462e-06,
      "loss": 0.3073,
      "step": 1400
    },
    {
      "epoch": 0.3984611156911239,
      "grad_norm": 0.08426138013601303,
      "learning_rate": 8.917773382311388e-06,
      "loss": 0.1531,
      "step": 1450
    },
    {
      "epoch": 0.41220115416323166,
      "grad_norm": 14.317792892456055,
      "learning_rate": 8.870679099557314e-06,
      "loss": 0.182,
      "step": 1500
    },
    {
      "epoch": 0.42594119263533936,
      "grad_norm": 0.8186487555503845,
      "learning_rate": 8.823584816803242e-06,
      "loss": 0.1466,
      "step": 1550
    },
    {
      "epoch": 0.4396812311074471,
      "grad_norm": 18.319841384887695,
      "learning_rate": 8.776490534049166e-06,
      "loss": 0.1921,
      "step": 1600
    },
    {
      "epoch": 0.4534212695795548,
      "grad_norm": 0.08368849754333496,
      "learning_rate": 8.729396251295094e-06,
      "loss": 0.1833,
      "step": 1650
    },
    {
      "epoch": 0.46716130805166256,
      "grad_norm": 1.79403817653656,
      "learning_rate": 8.68230196854102e-06,
      "loss": 0.2139,
      "step": 1700
    },
    {
      "epoch": 0.48090134652377026,
      "grad_norm": 13.724562644958496,
      "learning_rate": 8.635207685786947e-06,
      "loss": 0.1906,
      "step": 1750
    },
    {
      "epoch": 0.494641384995878,
      "grad_norm": 9.742436408996582,
      "learning_rate": 8.588113403032873e-06,
      "loss": 0.1533,
      "step": 1800
    },
    {
      "epoch": 0.5083814234679858,
      "grad_norm": 0.20854806900024414,
      "learning_rate": 8.541019120278799e-06,
      "loss": 0.1408,
      "step": 1850
    },
    {
      "epoch": 0.5221214619400935,
      "grad_norm": 0.11648739129304886,
      "learning_rate": 8.493924837524725e-06,
      "loss": 0.1799,
      "step": 1900
    },
    {
      "epoch": 0.5358615004122012,
      "grad_norm": 0.02938375435769558,
      "learning_rate": 8.446830554770652e-06,
      "loss": 0.1132,
      "step": 1950
    },
    {
      "epoch": 0.5496015388843088,
      "grad_norm": 0.03255586326122284,
      "learning_rate": 8.399736272016578e-06,
      "loss": 0.2667,
      "step": 2000
    },
    {
      "epoch": 0.5633415773564165,
      "grad_norm": 0.09896139055490494,
      "learning_rate": 8.352641989262504e-06,
      "loss": 0.1424,
      "step": 2050
    },
    {
      "epoch": 0.5770816158285244,
      "grad_norm": 0.09275360405445099,
      "learning_rate": 8.30554770650843e-06,
      "loss": 0.1446,
      "step": 2100
    },
    {
      "epoch": 0.590821654300632,
      "grad_norm": 39.59969711303711,
      "learning_rate": 8.258453423754356e-06,
      "loss": 0.1713,
      "step": 2150
    },
    {
      "epoch": 0.6045616927727397,
      "grad_norm": 0.7177359461784363,
      "learning_rate": 8.211359141000284e-06,
      "loss": 0.0984,
      "step": 2200
    },
    {
      "epoch": 0.6183017312448474,
      "grad_norm": 49.079681396484375,
      "learning_rate": 8.164264858246209e-06,
      "loss": 0.1811,
      "step": 2250
    },
    {
      "epoch": 0.6320417697169552,
      "grad_norm": 25.57713508605957,
      "learning_rate": 8.117170575492135e-06,
      "loss": 0.1492,
      "step": 2300
    },
    {
      "epoch": 0.645781808189063,
      "grad_norm": 29.069976806640625,
      "learning_rate": 8.070076292738063e-06,
      "loss": 0.2038,
      "step": 2350
    },
    {
      "epoch": 0.6595218466611706,
      "grad_norm": 4.703706741333008,
      "learning_rate": 8.022982009983988e-06,
      "loss": 0.1579,
      "step": 2400
    },
    {
      "epoch": 0.6732618851332783,
      "grad_norm": 53.392356872558594,
      "learning_rate": 7.975887727229915e-06,
      "loss": 0.1916,
      "step": 2450
    },
    {
      "epoch": 0.6870019236053861,
      "grad_norm": 0.09075982868671417,
      "learning_rate": 7.92879344447584e-06,
      "loss": 0.1582,
      "step": 2500
    },
    {
      "epoch": 0.7007419620774938,
      "grad_norm": 8.762046813964844,
      "learning_rate": 7.881699161721768e-06,
      "loss": 0.2129,
      "step": 2550
    },
    {
      "epoch": 0.7144820005496015,
      "grad_norm": 0.4255253076553345,
      "learning_rate": 7.834604878967694e-06,
      "loss": 0.1245,
      "step": 2600
    },
    {
      "epoch": 0.7282220390217092,
      "grad_norm": 0.029928814619779587,
      "learning_rate": 7.78751059621362e-06,
      "loss": 0.1374,
      "step": 2650
    },
    {
      "epoch": 0.7419620774938169,
      "grad_norm": 1.2551265954971313,
      "learning_rate": 7.740416313459547e-06,
      "loss": 0.1698,
      "step": 2700
    },
    {
      "epoch": 0.7557021159659247,
      "grad_norm": 38.74884033203125,
      "learning_rate": 7.693322030705473e-06,
      "loss": 0.1292,
      "step": 2750
    },
    {
      "epoch": 0.7694421544380324,
      "grad_norm": 0.018076233565807343,
      "learning_rate": 7.646227747951399e-06,
      "loss": 0.1265,
      "step": 2800
    },
    {
      "epoch": 0.7831821929101401,
      "grad_norm": 12.16530704498291,
      "learning_rate": 7.599133465197326e-06,
      "loss": 0.1918,
      "step": 2850
    },
    {
      "epoch": 0.7969222313822478,
      "grad_norm": 0.06284032016992569,
      "learning_rate": 7.552039182443251e-06,
      "loss": 0.1838,
      "step": 2900
    },
    {
      "epoch": 0.8106622698543556,
      "grad_norm": 4.303733825683594,
      "learning_rate": 7.5049448996891785e-06,
      "loss": 0.0993,
      "step": 2950
    },
    {
      "epoch": 0.8244023083264633,
      "grad_norm": 17.671188354492188,
      "learning_rate": 7.457850616935105e-06,
      "loss": 0.2026,
      "step": 3000
    },
    {
      "epoch": 0.838142346798571,
      "grad_norm": 45.796783447265625,
      "learning_rate": 7.410756334181031e-06,
      "loss": 0.2012,
      "step": 3050
    },
    {
      "epoch": 0.8518823852706787,
      "grad_norm": 4.688870429992676,
      "learning_rate": 7.363662051426957e-06,
      "loss": 0.161,
      "step": 3100
    },
    {
      "epoch": 0.8656224237427865,
      "grad_norm": 11.649136543273926,
      "learning_rate": 7.316567768672884e-06,
      "loss": 0.1502,
      "step": 3150
    },
    {
      "epoch": 0.8793624622148942,
      "grad_norm": 0.1611730456352234,
      "learning_rate": 7.2694734859188095e-06,
      "loss": 0.1474,
      "step": 3200
    },
    {
      "epoch": 0.8931025006870019,
      "grad_norm": 13.643877983093262,
      "learning_rate": 7.222379203164737e-06,
      "loss": 0.1721,
      "step": 3250
    },
    {
      "epoch": 0.9068425391591096,
      "grad_norm": 83.33094787597656,
      "learning_rate": 7.175284920410662e-06,
      "loss": 0.1574,
      "step": 3300
    },
    {
      "epoch": 0.9205825776312173,
      "grad_norm": 4.787201404571533,
      "learning_rate": 7.128190637656589e-06,
      "loss": 0.1862,
      "step": 3350
    },
    {
      "epoch": 0.9343226161033251,
      "grad_norm": 0.013330822810530663,
      "learning_rate": 7.081096354902516e-06,
      "loss": 0.0883,
      "step": 3400
    },
    {
      "epoch": 0.9480626545754328,
      "grad_norm": 0.10052993148565292,
      "learning_rate": 7.0340020721484415e-06,
      "loss": 0.1831,
      "step": 3450
    },
    {
      "epoch": 0.9618026930475405,
      "grad_norm": 76.99364471435547,
      "learning_rate": 6.9869077893943685e-06,
      "loss": 0.1629,
      "step": 3500
    },
    {
      "epoch": 0.9755427315196482,
      "grad_norm": 4.9555277824401855,
      "learning_rate": 6.939813506640295e-06,
      "loss": 0.1294,
      "step": 3550
    },
    {
      "epoch": 0.989282769991756,
      "grad_norm": 0.04486240819096565,
      "learning_rate": 6.892719223886221e-06,
      "loss": 0.1477,
      "step": 3600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9165979664743061,
      "eval_f1": 0.909253999103005,
      "eval_loss": 0.3291667401790619,
      "eval_precision": 0.9947661105659142,
      "eval_recall": 0.8372797356828194,
      "eval_runtime": 241.5354,
      "eval_samples_per_second": 30.132,
      "eval_steps_per_second": 3.768,
      "step": 3639
    },
    {
      "epoch": 1.0030228084638637,
      "grad_norm": 0.04365087300539017,
      "learning_rate": 6.845624941132147e-06,
      "loss": 0.188,
      "step": 3650
    },
    {
      "epoch": 1.0167628469359715,
      "grad_norm": 49.23527908325195,
      "learning_rate": 6.798530658378073e-06,
      "loss": 0.0994,
      "step": 3700
    },
    {
      "epoch": 1.030502885408079,
      "grad_norm": 45.03071975708008,
      "learning_rate": 6.751436375624e-06,
      "loss": 0.0724,
      "step": 3750
    },
    {
      "epoch": 1.044242923880187,
      "grad_norm": 47.195674896240234,
      "learning_rate": 6.704342092869927e-06,
      "loss": 0.1282,
      "step": 3800
    },
    {
      "epoch": 1.0579829623522945,
      "grad_norm": 5.365055561065674,
      "learning_rate": 6.657247810115852e-06,
      "loss": 0.1732,
      "step": 3850
    },
    {
      "epoch": 1.0717230008244023,
      "grad_norm": 0.017967987805604935,
      "learning_rate": 6.610153527361779e-06,
      "loss": 0.1195,
      "step": 3900
    },
    {
      "epoch": 1.0854630392965101,
      "grad_norm": 47.506587982177734,
      "learning_rate": 6.563059244607705e-06,
      "loss": 0.0902,
      "step": 3950
    },
    {
      "epoch": 1.0992030777686177,
      "grad_norm": 0.014613369479775429,
      "learning_rate": 6.5159649618536316e-06,
      "loss": 0.1525,
      "step": 4000
    },
    {
      "epoch": 1.1129431162407255,
      "grad_norm": 1.8166648149490356,
      "learning_rate": 6.468870679099558e-06,
      "loss": 0.0995,
      "step": 4050
    },
    {
      "epoch": 1.126683154712833,
      "grad_norm": 0.0062952302396297455,
      "learning_rate": 6.421776396345484e-06,
      "loss": 0.0939,
      "step": 4100
    },
    {
      "epoch": 1.140423193184941,
      "grad_norm": 3.4425086975097656,
      "learning_rate": 6.37468211359141e-06,
      "loss": 0.1866,
      "step": 4150
    },
    {
      "epoch": 1.1541632316570487,
      "grad_norm": 16.853635787963867,
      "learning_rate": 6.327587830837337e-06,
      "loss": 0.1086,
      "step": 4200
    },
    {
      "epoch": 1.1679032701291563,
      "grad_norm": 0.242648184299469,
      "learning_rate": 6.280493548083263e-06,
      "loss": 0.1329,
      "step": 4250
    },
    {
      "epoch": 1.181643308601264,
      "grad_norm": 0.12062478810548782,
      "learning_rate": 6.23339926532919e-06,
      "loss": 0.0806,
      "step": 4300
    },
    {
      "epoch": 1.195383347073372,
      "grad_norm": 0.026124650612473488,
      "learning_rate": 6.186304982575115e-06,
      "loss": 0.2033,
      "step": 4350
    },
    {
      "epoch": 1.2091233855454795,
      "grad_norm": 2.4767494201660156,
      "learning_rate": 6.139210699821042e-06,
      "loss": 0.133,
      "step": 4400
    },
    {
      "epoch": 1.2228634240175873,
      "grad_norm": 0.046098921447992325,
      "learning_rate": 6.092116417066969e-06,
      "loss": 0.0792,
      "step": 4450
    },
    {
      "epoch": 1.2366034624896949,
      "grad_norm": 51.59554672241211,
      "learning_rate": 6.0450221343128946e-06,
      "loss": 0.1381,
      "step": 4500
    },
    {
      "epoch": 1.2503435009618027,
      "grad_norm": 0.10453599691390991,
      "learning_rate": 5.997927851558822e-06,
      "loss": 0.1128,
      "step": 4550
    },
    {
      "epoch": 1.2640835394339105,
      "grad_norm": 3.6784145832061768,
      "learning_rate": 5.950833568804748e-06,
      "loss": 0.1501,
      "step": 4600
    },
    {
      "epoch": 1.277823577906018,
      "grad_norm": 0.3366086184978485,
      "learning_rate": 5.903739286050674e-06,
      "loss": 0.1295,
      "step": 4650
    },
    {
      "epoch": 1.291563616378126,
      "grad_norm": 42.92313003540039,
      "learning_rate": 5.8566450032966e-06,
      "loss": 0.0906,
      "step": 4700
    },
    {
      "epoch": 1.3053036548502335,
      "grad_norm": 0.031525399535894394,
      "learning_rate": 5.8095507205425265e-06,
      "loss": 0.1507,
      "step": 4750
    },
    {
      "epoch": 1.3190436933223413,
      "grad_norm": 0.18444161117076874,
      "learning_rate": 5.762456437788453e-06,
      "loss": 0.1217,
      "step": 4800
    },
    {
      "epoch": 1.332783731794449,
      "grad_norm": 0.01677115261554718,
      "learning_rate": 5.71536215503438e-06,
      "loss": 0.1132,
      "step": 4850
    },
    {
      "epoch": 1.3465237702665567,
      "grad_norm": 0.10729019343852997,
      "learning_rate": 5.668267872280305e-06,
      "loss": 0.1433,
      "step": 4900
    },
    {
      "epoch": 1.3602638087386645,
      "grad_norm": 10.81590747833252,
      "learning_rate": 5.621173589526232e-06,
      "loss": 0.1155,
      "step": 4950
    },
    {
      "epoch": 1.3740038472107723,
      "grad_norm": 0.558735191822052,
      "learning_rate": 5.5740793067721584e-06,
      "loss": 0.1236,
      "step": 5000
    },
    {
      "epoch": 1.3877438856828799,
      "grad_norm": 0.02289494127035141,
      "learning_rate": 5.526985024018085e-06,
      "loss": 0.1328,
      "step": 5050
    },
    {
      "epoch": 1.4014839241549877,
      "grad_norm": 0.045825134962797165,
      "learning_rate": 5.479890741264011e-06,
      "loss": 0.1418,
      "step": 5100
    },
    {
      "epoch": 1.4152239626270955,
      "grad_norm": 0.0433315634727478,
      "learning_rate": 5.432796458509937e-06,
      "loss": 0.0523,
      "step": 5150
    },
    {
      "epoch": 1.428964001099203,
      "grad_norm": 0.011303693056106567,
      "learning_rate": 5.385702175755863e-06,
      "loss": 0.1125,
      "step": 5200
    },
    {
      "epoch": 1.4427040395713109,
      "grad_norm": 44.306331634521484,
      "learning_rate": 5.33860789300179e-06,
      "loss": 0.1653,
      "step": 5250
    },
    {
      "epoch": 1.4564440780434185,
      "grad_norm": 0.022035682573914528,
      "learning_rate": 5.291513610247716e-06,
      "loss": 0.1623,
      "step": 5300
    },
    {
      "epoch": 1.4701841165155263,
      "grad_norm": 0.015996603295207024,
      "learning_rate": 5.244419327493643e-06,
      "loss": 0.128,
      "step": 5350
    },
    {
      "epoch": 1.4839241549876339,
      "grad_norm": 0.06968028098344803,
      "learning_rate": 5.19732504473957e-06,
      "loss": 0.1176,
      "step": 5400
    },
    {
      "epoch": 1.4976641934597417,
      "grad_norm": 0.06430471688508987,
      "learning_rate": 5.150230761985495e-06,
      "loss": 0.1496,
      "step": 5450
    },
    {
      "epoch": 1.5114042319318495,
      "grad_norm": 0.03961526229977608,
      "learning_rate": 5.103136479231422e-06,
      "loss": 0.1324,
      "step": 5500
    },
    {
      "epoch": 1.525144270403957,
      "grad_norm": 5.566534042358398,
      "learning_rate": 5.056042196477348e-06,
      "loss": 0.0658,
      "step": 5550
    },
    {
      "epoch": 1.5388843088760649,
      "grad_norm": 0.023576028645038605,
      "learning_rate": 5.008947913723275e-06,
      "loss": 0.1703,
      "step": 5600
    },
    {
      "epoch": 1.5526243473481727,
      "grad_norm": 0.024222465232014656,
      "learning_rate": 4.961853630969201e-06,
      "loss": 0.1056,
      "step": 5650
    },
    {
      "epoch": 1.5663643858202803,
      "grad_norm": 23.49598503112793,
      "learning_rate": 4.914759348215127e-06,
      "loss": 0.0968,
      "step": 5700
    },
    {
      "epoch": 1.580104424292388,
      "grad_norm": 2.6299288272857666,
      "learning_rate": 4.867665065461053e-06,
      "loss": 0.0836,
      "step": 5750
    },
    {
      "epoch": 1.5938444627644959,
      "grad_norm": 0.028310230001807213,
      "learning_rate": 4.82057078270698e-06,
      "loss": 0.1139,
      "step": 5800
    },
    {
      "epoch": 1.6075845012366035,
      "grad_norm": 0.019218219444155693,
      "learning_rate": 4.773476499952906e-06,
      "loss": 0.1111,
      "step": 5850
    },
    {
      "epoch": 1.621324539708711,
      "grad_norm": 0.03632602468132973,
      "learning_rate": 4.726382217198833e-06,
      "loss": 0.1169,
      "step": 5900
    },
    {
      "epoch": 1.635064578180819,
      "grad_norm": 0.0224856436252594,
      "learning_rate": 4.679287934444759e-06,
      "loss": 0.1345,
      "step": 5950
    },
    {
      "epoch": 1.6488046166529267,
      "grad_norm": 0.0887979045510292,
      "learning_rate": 4.632193651690685e-06,
      "loss": 0.1243,
      "step": 6000
    },
    {
      "epoch": 1.6625446551250342,
      "grad_norm": 53.025413513183594,
      "learning_rate": 4.5850993689366115e-06,
      "loss": 0.096,
      "step": 6050
    },
    {
      "epoch": 1.676284693597142,
      "grad_norm": 6.777423858642578,
      "learning_rate": 4.538005086182538e-06,
      "loss": 0.099,
      "step": 6100
    },
    {
      "epoch": 1.6900247320692499,
      "grad_norm": 0.021374981850385666,
      "learning_rate": 4.490910803428464e-06,
      "loss": 0.1036,
      "step": 6150
    },
    {
      "epoch": 1.7037647705413574,
      "grad_norm": 0.10440198332071304,
      "learning_rate": 4.44381652067439e-06,
      "loss": 0.0656,
      "step": 6200
    },
    {
      "epoch": 1.7175048090134653,
      "grad_norm": 0.03010641410946846,
      "learning_rate": 4.396722237920316e-06,
      "loss": 0.1123,
      "step": 6250
    },
    {
      "epoch": 1.731244847485573,
      "grad_norm": 0.4392932057380676,
      "learning_rate": 4.349627955166243e-06,
      "loss": 0.1345,
      "step": 6300
    },
    {
      "epoch": 1.7449848859576806,
      "grad_norm": 27.944791793823242,
      "learning_rate": 4.30253367241217e-06,
      "loss": 0.1672,
      "step": 6350
    },
    {
      "epoch": 1.7587249244297884,
      "grad_norm": 14.645423889160156,
      "learning_rate": 4.255439389658096e-06,
      "loss": 0.1332,
      "step": 6400
    },
    {
      "epoch": 1.7724649629018963,
      "grad_norm": 0.23295320570468903,
      "learning_rate": 4.208345106904022e-06,
      "loss": 0.0917,
      "step": 6450
    },
    {
      "epoch": 1.7862050013740038,
      "grad_norm": 74.76704406738281,
      "learning_rate": 4.161250824149948e-06,
      "loss": 0.1645,
      "step": 6500
    },
    {
      "epoch": 1.7999450398461114,
      "grad_norm": 0.02352781407535076,
      "learning_rate": 4.114156541395875e-06,
      "loss": 0.095,
      "step": 6550
    },
    {
      "epoch": 1.8136850783182195,
      "grad_norm": 0.3514206111431122,
      "learning_rate": 4.067062258641802e-06,
      "loss": 0.0889,
      "step": 6600
    },
    {
      "epoch": 1.827425116790327,
      "grad_norm": 16.059873580932617,
      "learning_rate": 4.019967975887728e-06,
      "loss": 0.1411,
      "step": 6650
    },
    {
      "epoch": 1.8411651552624346,
      "grad_norm": 11.652234077453613,
      "learning_rate": 3.972873693133654e-06,
      "loss": 0.0913,
      "step": 6700
    },
    {
      "epoch": 1.8549051937345424,
      "grad_norm": 9.785456657409668,
      "learning_rate": 3.92577941037958e-06,
      "loss": 0.1067,
      "step": 6750
    },
    {
      "epoch": 1.8686452322066502,
      "grad_norm": 10.384054183959961,
      "learning_rate": 3.8786851276255065e-06,
      "loss": 0.0858,
      "step": 6800
    },
    {
      "epoch": 1.8823852706787578,
      "grad_norm": 1.2080868482589722,
      "learning_rate": 3.831590844871433e-06,
      "loss": 0.0952,
      "step": 6850
    },
    {
      "epoch": 1.8961253091508656,
      "grad_norm": 0.09168172627687454,
      "learning_rate": 3.784496562117359e-06,
      "loss": 0.0977,
      "step": 6900
    },
    {
      "epoch": 1.9098653476229734,
      "grad_norm": 0.023567460477352142,
      "learning_rate": 3.737402279363286e-06,
      "loss": 0.0995,
      "step": 6950
    },
    {
      "epoch": 1.923605386095081,
      "grad_norm": 0.03584348037838936,
      "learning_rate": 3.690307996609212e-06,
      "loss": 0.0732,
      "step": 7000
    },
    {
      "epoch": 1.9373454245671888,
      "grad_norm": 0.14036086201667786,
      "learning_rate": 3.6432137138551384e-06,
      "loss": 0.1066,
      "step": 7050
    },
    {
      "epoch": 1.9510854630392966,
      "grad_norm": 0.011295539326965809,
      "learning_rate": 3.5961194311010646e-06,
      "loss": 0.0675,
      "step": 7100
    },
    {
      "epoch": 1.9648255015114042,
      "grad_norm": 5.928492546081543,
      "learning_rate": 3.5490251483469913e-06,
      "loss": 0.1533,
      "step": 7150
    },
    {
      "epoch": 1.9785655399835118,
      "grad_norm": 0.13684876263141632,
      "learning_rate": 3.5019308655929175e-06,
      "loss": 0.0594,
      "step": 7200
    },
    {
      "epoch": 1.9923055784556198,
      "grad_norm": 0.03405845910310745,
      "learning_rate": 3.4548365828388437e-06,
      "loss": 0.1243,
      "step": 7250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8871942841439956,
      "eval_f1": 0.8731262556019163,
      "eval_loss": 0.6392502188682556,
      "eval_precision": 0.9950686861570975,
      "eval_recall": 0.7778083700440529,
      "eval_runtime": 249.0729,
      "eval_samples_per_second": 29.22,
      "eval_steps_per_second": 3.654,
      "step": 7278
    },
    {
      "epoch": 2.0060456169277274,
      "grad_norm": 22.072223663330078,
      "learning_rate": 3.40774230008477e-06,
      "loss": 0.1031,
      "step": 7300
    },
    {
      "epoch": 2.019785655399835,
      "grad_norm": 3.9092631340026855,
      "learning_rate": 3.3606480173306966e-06,
      "loss": 0.0612,
      "step": 7350
    },
    {
      "epoch": 2.033525693871943,
      "grad_norm": 0.01097832154482603,
      "learning_rate": 3.3135537345766228e-06,
      "loss": 0.1019,
      "step": 7400
    },
    {
      "epoch": 2.0472657323440506,
      "grad_norm": 0.6452462673187256,
      "learning_rate": 3.266459451822549e-06,
      "loss": 0.1018,
      "step": 7450
    },
    {
      "epoch": 2.061005770816158,
      "grad_norm": 0.6272584199905396,
      "learning_rate": 3.219365169068475e-06,
      "loss": 0.1077,
      "step": 7500
    },
    {
      "epoch": 2.074745809288266,
      "grad_norm": 74.79012298583984,
      "learning_rate": 3.172270886314402e-06,
      "loss": 0.1051,
      "step": 7550
    },
    {
      "epoch": 2.088485847760374,
      "grad_norm": 0.9269012808799744,
      "learning_rate": 3.125176603560328e-06,
      "loss": 0.0886,
      "step": 7600
    },
    {
      "epoch": 2.1022258862324814,
      "grad_norm": 0.03442452475428581,
      "learning_rate": 3.0780823208062543e-06,
      "loss": 0.0664,
      "step": 7650
    },
    {
      "epoch": 2.115965924704589,
      "grad_norm": 0.8226323127746582,
      "learning_rate": 3.0309880380521805e-06,
      "loss": 0.0905,
      "step": 7700
    },
    {
      "epoch": 2.129705963176697,
      "grad_norm": 0.5854763984680176,
      "learning_rate": 2.983893755298107e-06,
      "loss": 0.0993,
      "step": 7750
    },
    {
      "epoch": 2.1434460016488046,
      "grad_norm": 0.25425949692726135,
      "learning_rate": 2.9367994725440334e-06,
      "loss": 0.1257,
      "step": 7800
    },
    {
      "epoch": 2.157186040120912,
      "grad_norm": 59.898868560791016,
      "learning_rate": 2.8897051897899596e-06,
      "loss": 0.1388,
      "step": 7850
    },
    {
      "epoch": 2.1709260785930202,
      "grad_norm": 0.006332342978566885,
      "learning_rate": 2.842610907035886e-06,
      "loss": 0.1093,
      "step": 7900
    },
    {
      "epoch": 2.184666117065128,
      "grad_norm": 0.055329788476228714,
      "learning_rate": 2.795516624281812e-06,
      "loss": 0.0588,
      "step": 7950
    },
    {
      "epoch": 2.1984061555372354,
      "grad_norm": 25.81188201904297,
      "learning_rate": 2.748422341527739e-06,
      "loss": 0.1101,
      "step": 8000
    },
    {
      "epoch": 2.2121461940093434,
      "grad_norm": 33.05021667480469,
      "learning_rate": 2.7013280587736653e-06,
      "loss": 0.0903,
      "step": 8050
    },
    {
      "epoch": 2.225886232481451,
      "grad_norm": 0.22734878957271576,
      "learning_rate": 2.6542337760195915e-06,
      "loss": 0.0859,
      "step": 8100
    },
    {
      "epoch": 2.2396262709535586,
      "grad_norm": 0.030041545629501343,
      "learning_rate": 2.6071394932655177e-06,
      "loss": 0.058,
      "step": 8150
    },
    {
      "epoch": 2.253366309425666,
      "grad_norm": 0.020551448687911034,
      "learning_rate": 2.5600452105114444e-06,
      "loss": 0.0456,
      "step": 8200
    },
    {
      "epoch": 2.267106347897774,
      "grad_norm": 31.785560607910156,
      "learning_rate": 2.5129509277573706e-06,
      "loss": 0.1185,
      "step": 8250
    },
    {
      "epoch": 2.280846386369882,
      "grad_norm": 0.07188814878463745,
      "learning_rate": 2.465856645003297e-06,
      "loss": 0.0713,
      "step": 8300
    },
    {
      "epoch": 2.2945864248419894,
      "grad_norm": 0.04310009628534317,
      "learning_rate": 2.418762362249223e-06,
      "loss": 0.1201,
      "step": 8350
    },
    {
      "epoch": 2.3083264633140974,
      "grad_norm": 0.6207488179206848,
      "learning_rate": 2.3716680794951492e-06,
      "loss": 0.0994,
      "step": 8400
    },
    {
      "epoch": 2.322066501786205,
      "grad_norm": 0.1908521205186844,
      "learning_rate": 2.324573796741076e-06,
      "loss": 0.0656,
      "step": 8450
    },
    {
      "epoch": 2.3358065402583126,
      "grad_norm": 0.02558785118162632,
      "learning_rate": 2.277479513987002e-06,
      "loss": 0.073,
      "step": 8500
    },
    {
      "epoch": 2.3495465787304206,
      "grad_norm": 0.008840516209602356,
      "learning_rate": 2.2303852312329287e-06,
      "loss": 0.0649,
      "step": 8550
    },
    {
      "epoch": 2.363286617202528,
      "grad_norm": 0.028281493112444878,
      "learning_rate": 2.183290948478855e-06,
      "loss": 0.0546,
      "step": 8600
    },
    {
      "epoch": 2.377026655674636,
      "grad_norm": 0.13589228689670563,
      "learning_rate": 2.136196665724781e-06,
      "loss": 0.0719,
      "step": 8650
    },
    {
      "epoch": 2.390766694146744,
      "grad_norm": 0.01233321987092495,
      "learning_rate": 2.0891023829707074e-06,
      "loss": 0.0577,
      "step": 8700
    },
    {
      "epoch": 2.4045067326188514,
      "grad_norm": 0.4869650602340698,
      "learning_rate": 2.042008100216634e-06,
      "loss": 0.0926,
      "step": 8750
    },
    {
      "epoch": 2.418246771090959,
      "grad_norm": 0.2371995449066162,
      "learning_rate": 1.9949138174625602e-06,
      "loss": 0.0973,
      "step": 8800
    },
    {
      "epoch": 2.4319868095630666,
      "grad_norm": 0.02732579968869686,
      "learning_rate": 1.9478195347084865e-06,
      "loss": 0.0736,
      "step": 8850
    },
    {
      "epoch": 2.4457268480351746,
      "grad_norm": 0.036720313131809235,
      "learning_rate": 1.9007252519544129e-06,
      "loss": 0.0916,
      "step": 8900
    },
    {
      "epoch": 2.459466886507282,
      "grad_norm": 0.0062310462817549706,
      "learning_rate": 1.8536309692003393e-06,
      "loss": 0.0681,
      "step": 8950
    },
    {
      "epoch": 2.4732069249793898,
      "grad_norm": 0.023959744721651077,
      "learning_rate": 1.8065366864462655e-06,
      "loss": 0.0492,
      "step": 9000
    },
    {
      "epoch": 2.486946963451498,
      "grad_norm": 0.16585862636566162,
      "learning_rate": 1.759442403692192e-06,
      "loss": 0.0915,
      "step": 9050
    },
    {
      "epoch": 2.5006870019236054,
      "grad_norm": 27.07786750793457,
      "learning_rate": 1.7123481209381182e-06,
      "loss": 0.1396,
      "step": 9100
    },
    {
      "epoch": 2.514427040395713,
      "grad_norm": 0.019718721508979797,
      "learning_rate": 1.6652538381840446e-06,
      "loss": 0.0972,
      "step": 9150
    },
    {
      "epoch": 2.528167078867821,
      "grad_norm": 28.384687423706055,
      "learning_rate": 1.6181595554299708e-06,
      "loss": 0.1281,
      "step": 9200
    },
    {
      "epoch": 2.5419071173399286,
      "grad_norm": 0.03265472874045372,
      "learning_rate": 1.5710652726758975e-06,
      "loss": 0.0285,
      "step": 9250
    },
    {
      "epoch": 2.555647155812036,
      "grad_norm": 0.09761448204517365,
      "learning_rate": 1.5239709899218237e-06,
      "loss": 0.0351,
      "step": 9300
    },
    {
      "epoch": 2.569387194284144,
      "grad_norm": 0.1015402227640152,
      "learning_rate": 1.47687670716775e-06,
      "loss": 0.0982,
      "step": 9350
    },
    {
      "epoch": 2.583127232756252,
      "grad_norm": 0.025796592235565186,
      "learning_rate": 1.4297824244136763e-06,
      "loss": 0.0463,
      "step": 9400
    },
    {
      "epoch": 2.5968672712283594,
      "grad_norm": 55.85846710205078,
      "learning_rate": 1.3826881416596027e-06,
      "loss": 0.0435,
      "step": 9450
    },
    {
      "epoch": 2.610607309700467,
      "grad_norm": 0.009099780581891537,
      "learning_rate": 1.335593858905529e-06,
      "loss": 0.0472,
      "step": 9500
    },
    {
      "epoch": 2.624347348172575,
      "grad_norm": 0.2031855285167694,
      "learning_rate": 1.2884995761514554e-06,
      "loss": 0.0363,
      "step": 9550
    },
    {
      "epoch": 2.6380873866446826,
      "grad_norm": 25.668411254882812,
      "learning_rate": 1.2414052933973816e-06,
      "loss": 0.1158,
      "step": 9600
    },
    {
      "epoch": 2.6518274251167906,
      "grad_norm": 0.01038428395986557,
      "learning_rate": 1.194311010643308e-06,
      "loss": 0.0793,
      "step": 9650
    },
    {
      "epoch": 2.665567463588898,
      "grad_norm": 0.005770597606897354,
      "learning_rate": 1.1472167278892343e-06,
      "loss": 0.1028,
      "step": 9700
    },
    {
      "epoch": 2.6793075020610058,
      "grad_norm": 0.04260268807411194,
      "learning_rate": 1.1001224451351607e-06,
      "loss": 0.0642,
      "step": 9750
    },
    {
      "epoch": 2.6930475405331133,
      "grad_norm": 0.02608254738152027,
      "learning_rate": 1.0530281623810871e-06,
      "loss": 0.1341,
      "step": 9800
    },
    {
      "epoch": 2.7067875790052214,
      "grad_norm": 0.02011554315686226,
      "learning_rate": 1.0059338796270133e-06,
      "loss": 0.0518,
      "step": 9850
    },
    {
      "epoch": 2.720527617477329,
      "grad_norm": 19.644372940063477,
      "learning_rate": 9.588395968729398e-07,
      "loss": 0.0786,
      "step": 9900
    },
    {
      "epoch": 2.7342676559494365,
      "grad_norm": 0.011507676914334297,
      "learning_rate": 9.117453141188661e-07,
      "loss": 0.0923,
      "step": 9950
    },
    {
      "epoch": 2.7480076944215446,
      "grad_norm": 0.00951087474822998,
      "learning_rate": 8.646510313647924e-07,
      "loss": 0.0784,
      "step": 10000
    },
    {
      "epoch": 2.761747732893652,
      "grad_norm": 0.09027935564517975,
      "learning_rate": 8.175567486107187e-07,
      "loss": 0.1214,
      "step": 10050
    },
    {
      "epoch": 2.7754877713657597,
      "grad_norm": 0.15608248114585876,
      "learning_rate": 7.70462465856645e-07,
      "loss": 0.0774,
      "step": 10100
    },
    {
      "epoch": 2.7892278098378673,
      "grad_norm": 0.08692532032728195,
      "learning_rate": 7.233681831025714e-07,
      "loss": 0.0633,
      "step": 10150
    },
    {
      "epoch": 2.8029678483099754,
      "grad_norm": 0.006341456435620785,
      "learning_rate": 6.762739003484978e-07,
      "loss": 0.0646,
      "step": 10200
    },
    {
      "epoch": 2.816707886782083,
      "grad_norm": 0.033621594309806824,
      "learning_rate": 6.291796175944241e-07,
      "loss": 0.1097,
      "step": 10250
    },
    {
      "epoch": 2.830447925254191,
      "grad_norm": 0.00989137589931488,
      "learning_rate": 5.820853348403504e-07,
      "loss": 0.083,
      "step": 10300
    },
    {
      "epoch": 2.8441879637262986,
      "grad_norm": 0.07078655064105988,
      "learning_rate": 5.349910520862768e-07,
      "loss": 0.038,
      "step": 10350
    },
    {
      "epoch": 2.857928002198406,
      "grad_norm": 6.8618574142456055,
      "learning_rate": 4.878967693322031e-07,
      "loss": 0.0919,
      "step": 10400
    },
    {
      "epoch": 2.8716680406705137,
      "grad_norm": 0.10950085520744324,
      "learning_rate": 4.408024865781294e-07,
      "loss": 0.1419,
      "step": 10450
    },
    {
      "epoch": 2.8854080791426218,
      "grad_norm": 74.60952758789062,
      "learning_rate": 3.937082038240558e-07,
      "loss": 0.0833,
      "step": 10500
    },
    {
      "epoch": 2.8991481176147293,
      "grad_norm": 6.035893440246582,
      "learning_rate": 3.466139210699821e-07,
      "loss": 0.112,
      "step": 10550
    },
    {
      "epoch": 2.912888156086837,
      "grad_norm": 0.014854060485959053,
      "learning_rate": 2.995196383159085e-07,
      "loss": 0.1421,
      "step": 10600
    },
    {
      "epoch": 2.926628194558945,
      "grad_norm": 21.443115234375,
      "learning_rate": 2.524253555618348e-07,
      "loss": 0.0523,
      "step": 10650
    },
    {
      "epoch": 2.9403682330310525,
      "grad_norm": 0.008318529464304447,
      "learning_rate": 2.0533107280776114e-07,
      "loss": 0.096,
      "step": 10700
    },
    {
      "epoch": 2.95410827150316,
      "grad_norm": 0.014414861798286438,
      "learning_rate": 1.5823679005368748e-07,
      "loss": 0.0693,
      "step": 10750
    },
    {
      "epoch": 2.9678483099752677,
      "grad_norm": 0.020457426086068153,
      "learning_rate": 1.1114250729961383e-07,
      "loss": 0.0842,
      "step": 10800
    },
    {
      "epoch": 2.9815883484473757,
      "grad_norm": 24.31865119934082,
      "learning_rate": 6.404822454554017e-08,
      "loss": 0.1026,
      "step": 10850
    },
    {
      "epoch": 2.9953283869194833,
      "grad_norm": 45.170005798339844,
      "learning_rate": 1.6953941791466516e-08,
      "loss": 0.0617,
      "step": 10900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8888430887606485,
      "eval_f1": 0.8751350517055101,
      "eval_loss": 0.6723462343215942,
      "eval_precision": 0.9957850368809273,
      "eval_recall": 0.7805616740088106,
      "eval_runtime": 257.3583,
      "eval_samples_per_second": 28.28,
      "eval_steps_per_second": 3.536,
      "step": 10917
    }
  ],
  "logging_steps": 50,
  "max_steps": 10917,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 2
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.297827779775488e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
